{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b037d199-eff5-4761-a078-d2651e142ec8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 0 牛津朗文3k，五类词频3k，高中，取交集 ### <font color=\"#F08080\">991</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919201d1-7673-4699-bf9b-8b7c0140b7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f9055-e775-4b75-8548-1bb431d952a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import xlrd\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d41cf2-725b-4f22-85a8-661fadef583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import xlrd\n",
    "lm3k = pd.read_excel(\"./lm3k.xlsx\",header=None)\n",
    "\n",
    "#lm3k =lm3k.values.tolist()\n",
    "# 去除换行符\n",
    "#lm3k = [str(item).replace('\\n', '') for item in lm3k]\n",
    "#lm3k = [str(item).strip() for item in lm3k]\n",
    "\n",
    "lm3k = lm3k[0].str.strip()\n",
    "lm3k =lm3k.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385baee7-5fbe-47f0-85ed-8321bfabf3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('of3k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "of3k= [file.rstrip('\\n') for file in file] \n",
    "with open('highschool.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "high= [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149499ba-8af7-4c89-a820-bb0e8d84e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x for x in lm3k if x in of3k]\n",
    "data = [x for x in data if x in high]\n",
    "with open(\"stage0.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766c44f2-058a-4bf4-a091-427802768d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import xlrd\n",
    "lm3k = pd.read_excel(\"./lm3k.xlsx\",header=None)\n",
    "\n",
    "#lm3k =lm3k.values.tolist()\n",
    "# 去除换行符\n",
    "#lm3k = [str(item).replace('\\n', '') for item in lm3k]\n",
    "#lm3k = [str(item).strip() for item in lm3k]\n",
    "\n",
    "lm3k = lm3k[0].str.strip()\n",
    "lm3k =lm3k.values.tolist()\n",
    "\n",
    "with open('of3k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "of3k= [file.rstrip('\\n') for file in file] \n",
    "with open('highschool.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "high= [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8f9043-d9a6-4d24-b5f8-b2ceda1c9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x for x in bnc if x in coca]\n",
    "data = [x for x in data if x in google]\n",
    "data = [x for x in data if x in iweb]\n",
    "data = [x for x in data if x in SUBTLEXus]\n",
    "data = [x for x in data if x in lm3k]\n",
    "data = [x for x in data if x in of3k]\n",
    "data = [x for x in data if x in high]\n",
    "with open(\"stage030h.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ac26ce-4c47-4fdf-a2f0-068f1e70e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 2, 3, 4, 5]\n",
    "list2 = [4, 5, 6, 7, 8]\n",
    "with open('stage0300000.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "nh = [file.rstrip('\\n') for file in file] \n",
    "with open('stage030h.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "h = [file.rstrip('\\n') for file in file] \n",
    "\n",
    "# 转换为集合\n",
    "set1 = set(nh)\n",
    "set2 = set(h)\n",
    "\n",
    "# 获取对称差\n",
    "diff = set1.symmetric_difference(set2)\n",
    "\n",
    "# 转换回列表\n",
    "diff_list = list(diff)\n",
    "\n",
    "with open(\"stage0diff.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(diff_list))\n",
    "#diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf04825-20ba-4074-a01d-61c654b495b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ece843-8774-4014-a056-d993dc8e4232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "146e6ff7-6ee9-4ebe-bd5f-23a68bc8b373",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 1 牛津朗文3k，五类词频3k，取并集 ### <font color=\"#F08080\">6719</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea5cbf-aae1-430a-9390-3cc6ad6f5fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5a60f7-f9bd-40e5-bc7a-70942c19ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "lm3k = pd.read_excel(\"./lm3k.xlsx\",header=None)\n",
    "\n",
    "#lm3k =lm3k.values.tolist()\n",
    "# 去除换行符\n",
    "#lm3k = [str(item).replace('\\n', '') for item in lm3k]\n",
    "#lm3k = [str(item).strip() for item in lm3k]\n",
    "\n",
    "lm3k = lm3k[0].str.strip()\n",
    "lm3k =lm3k.values.tolist()\n",
    "\n",
    "with open('of3k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "of3k= [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('3kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a348d6-7273-4944-acf0-e7c8a1458e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = list(set(of3k + lm3k + bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage1.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(stage1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fd5382-4980-4054-a1ab-1da068360130",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = list(set(of3k + lm3k))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage00.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(stage1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb2ec4a-94ac-4d88-acf2-cafd4be6bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = list(set(of3k + lm3k))\n",
    "data = [x for x in stage1 if x in high]\n",
    "#data = [x for x in data if x in high]\n",
    "with open(\"stage00000000.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10396f2d-9ffb-4b5b-8522-70edd9c5cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('highschool.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "high= [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501edb2-064f-460e-8792-e50dc1bd6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x for x in stage1 if x in high]\n",
    "#data = [x for x in data if x in high]\n",
    "with open(\"stage00000000.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7525caa-9978-4137-9d9a-8f310ba8394c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 2 牛津5k，麦克米伦7.5k，CEFR, 五类词频6k，取并集 ### <font color=\"#F08080\">14984</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8fc0e7-a525-4c13-87f6-ac5434962585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "\n",
    "with open('oxford5000.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "of5k= [file.rstrip('\\n') for file in file] \n",
    "with open('macmillan7500.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "mk75k= [file.rstrip('\\n') for file in file] \n",
    "with open('2cefr.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "cefr= [file.rstrip('\\n') for file in file] \n",
    "with open('6kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('6kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('6kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('6kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('6kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aacdc47f-1a96-47e8-9583-2ed66b5a49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2 = list(set(of5k + mk75k + cefr+ bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage2.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(stage2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5341ac-ce3b-4f9d-a42b-1cae435a9668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4a1d744-97e8-4fd1-8b67-2b57c7bae116",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 3 朗文9k，四六级, 考研，五类词频10k，取并集 ### <font color=\"#F08080\">19082</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dee83e79-0149-467a-bbc2-d91fd176c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "\n",
    "with open('longman9k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "lm9k= [file.rstrip('\\n') for file in file] \n",
    "with open('cet4.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "cet4= [file.rstrip('\\n') for file in file] \n",
    "with open('cet6.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "cet6= [file.rstrip('\\n') for file in file] \n",
    "with open('postgraduate.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "pg= [file.rstrip('\\n') for file in file] \n",
    "with open('10kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('10kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('10kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('10kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('10kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9825d67-ae2b-4603-86da-c3be1ccf301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3 = list(set(lm9k + cet4 + cet6 + pg + bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage3.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(stage3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b4412-9d0d-440c-87ef-e30ed0f8139a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c3673-939c-4876-aa60-ddf49751fc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36381cf-4ec0-4c7e-9a6e-dd0b7d054919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc074a21-8adf-4684-8cf7-9f6865044792",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 4 柯林斯1~5⭐，TOEFL，IELTS，五类词频15k，取并集 ### <font color=\"#F08080\">31590</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33914246-2524-4228-8b1e-869c02acbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "\n",
    "with open('ielts8000.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "ielts= [file.rstrip('\\n') for file in file] \n",
    "with open('toefl.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "toefl= [file.rstrip('\\n') for file in file] \n",
    "with open('collins-1.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "collins1 = [file.rstrip('\\n') for file in file] \n",
    "with open('collins-2.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "collins2 = [file.rstrip('\\n') for file in file] \n",
    "with open('collins-3.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "collins3 = [file.rstrip('\\n') for file in file] \n",
    "with open('collins-4.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "collins4 = [file.rstrip('\\n') for file in file] \n",
    "with open('collins-5.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "collins5 = [file.rstrip('\\n') for file in file] \n",
    "with open('15kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('15kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('15kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('15kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('15kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7460532b-66e7-44a5-ae97-ad43e8daef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage4 = list(set(ielts + toefl + collins1 + collins2+ collins3 + collins4+ collins5 + bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage4.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(stage4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e6ea73b-4ce6-4673-af33-902747177bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(set(bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"test.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bd740-0938-470b-986c-d74c67e0c4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13909e-9d46-4232-b222-b9ba7023b7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663861e5-ca03-4b4a-9134-7a222d07323e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f06f6c2-fc9f-4971-80cf-417ed96fce98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 5 专四，专八，五类词频25k，取并集 ### <font color=\"#F08080\">45190</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "813bd7ae-1d82-41cc-95e1-05351bcbf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "\n",
    "with open('gre.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "gre= [file.rstrip('\\n') for file in file] \n",
    "with open('tem48.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "tem48= [file.rstrip('\\n') for file in file] \n",
    "with open('25kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('25kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('25kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('25kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('25kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b834e8e-c514-4d15-b51f-105efd534b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage5 = list(set(tem48 + bnc + coca + google + iweb + SUBTLEXus))  #gre + \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage5.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(stage5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed6b9068-7e11-4fa5-b57f-03732e8c1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(set(bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"test.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ff333-7a80-4daf-997d-c5913e6db7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42591fcb-9de6-471f-abbd-7037ed3c5166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c97d1999-c1ce-4db7-bea2-d75630461f92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 6 GRE，五类词频40k，取并集 ### <font color=\"#F08080\">70362</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c733aaa-88e8-49a5-9f01-2b53ca22e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "\n",
    "with open('gre.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "gre= [file.rstrip('\\n') for file in file] \n",
    "with open('40kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('40kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('40kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('40kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('40kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eca3d4d9-972f-4247-b169-4024db2494f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage6 = list(set(gre +  bnc + coca + google + iweb + SUBTLEXus))  #gre + \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage6.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(stage6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edb3daa0-4e37-419d-bf11-9d92ee4fe298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adjunctive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>identities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mythic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recollected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70357</th>\n",
       "      <td>philosophically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70358</th>\n",
       "      <td>Nix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70359</th>\n",
       "      <td>neighborly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70360</th>\n",
       "      <td>permittivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70361</th>\n",
       "      <td>outfitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70362 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0           adjunctive\n",
       "1           identities\n",
       "2               mythic\n",
       "3           defamation\n",
       "4          recollected\n",
       "...                ...\n",
       "70357  philosophically\n",
       "70358              Nix\n",
       "70359       neighborly\n",
       "70360     permittivity\n",
       "70361        outfitter\n",
       "\n",
       "[70362 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage6 = pd.DataFrame(stage6)\n",
    "stage6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0193388-5f7a-4e09-8952-35266fd4b808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11c954cb-a1aa-4e05-9d5b-95a733c8acc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 7 五类词频60k，取并集 ### <font color=\"#F08080\">96147</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d44b7a79-6561-4ca5-b69d-214929e4f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "\n",
    "with open('60kfiltered_unibnc.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "bnc = [file.rstrip('\\n') for file in file] \n",
    "with open('47kfiltered_unicoca60k.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "coca = [file.rstrip('\\n') for file in file] \n",
    "with open('60kfiltered_google.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "google = [file.rstrip('\\n') for file in file] \n",
    "with open('51kfiltered_uniiweb.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "iweb = [file.rstrip('\\n') for file in file] \n",
    "with open('60kfiltered_SUBTLEXus.txt', 'r', encoding='utf-8') as file:\n",
    "    file = file.readlines()\n",
    "SUBTLEXus = [file.rstrip('\\n') for file in file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50707c45-f0ed-4c06-9c5f-8340eecf54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage7 = list(set(bnc + coca + google + iweb + SUBTLEXus))  \n",
    "#stage2 = pd.DataFrame(stage2,)\n",
    "with open(\"stage7.txt\", \"w\",encoding=\"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(stage7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185af278-1345-4c2c-8f4c-ce403f7d1ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d406328-d129-4d7b-9594-8bbdb154ebc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
